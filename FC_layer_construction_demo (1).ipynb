{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71kdFp0QgF4K"
      },
      "source": [
        "# Multi-Layer Perceptron\n",
        "In this class we will build/develop our first neural network, and try to understand various components associated with it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2yHcl5xgPV1"
      },
      "source": [
        "## Load the libraries\n",
        "Set your Random seeds using numpy and tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DPwxLR2gSLC"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for available Devices -- You need GPU's to perform matrix multiplication"
      ],
      "metadata": {
        "id": "rdZ8ICUkJ_5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV-3kEaggcO8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82f35d43-7b1f-4a3b-ed25-b61d57f22224"
      },
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw78jw6pDqSM"
      },
      "source": [
        "#Get number of Gpu's and id's in the system or else you can also use Nvidia-smi in command prompt.\n",
        "This applies if you work on server or your local system"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Dk_S2TMg_6_"
      },
      "source": [
        "## Generate random data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40XlFnwho7D8"
      },
      "source": [
        "size_input = 64\n",
        "size_hidden = 128\n",
        "size_output = 1\n",
        "number_of_train_examples = 1500\n",
        "number_of_dev_examples = 400\n",
        "number_of_test_examples = 400"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm23CzRihaW0"
      },
      "source": [
        "X_train = np.random.uniform(0,1,(number_of_train_examples , size_input))\n",
        "y_train = np.random.uniform(0,1, (number_of_train_examples))\n",
        "X_val = np.random.uniform(0,1,(number_of_dev_examples, size_input))\n",
        "y_val = np.random.uniform(0,1, (number_of_dev_examples))\n",
        "X_test = np.random.uniform(0,1, (number_of_test_examples, size_input))\n",
        "y_test = np.random.uniform(0,1, (number_of_test_examples))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aigqKFFF5BM2"
      },
      "source": [
        "# Split dataset into batches\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(16)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb4hOoVbnzSJ"
      },
      "source": [
        "## Build MLP using Eager Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht9_qpYipgHw"
      },
      "source": [
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, size_input, size_hidden, size_output, device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_hidden, self.size_output, self.device =\\\n",
        "    size_input, size_hidden, size_output, device\n",
        "    \n",
        "    # Initialize weights between input layer and hidden layer\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden]))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_hidden]))\n",
        "     # Initialize weights between hidden layer and output layer\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden, self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.b1, self.b2]\n",
        "    \n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "  \n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    return tf.losses.mean_squared_error(y_true_tf, y_pred_tf)\n",
        "  \n",
        "  def backward(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "        \n",
        "        \n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    #Remember to normalize your dataset before moving forward\n",
        "    # Compute values in hidden layer\n",
        "    what = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat = tf.nn.relu(what)\n",
        "    # Compute output\n",
        "    output = tf.matmul(hhat, self.W2) + self.b2\n",
        "    #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this\n",
        "    #Second add tf.Softmax(output) and then return this variable\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUDFOuNk618X"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZPVUu0YDa-_"
      },
      "source": [
        "# Set number of epochs\n",
        "NUM_EPOCHS = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moAeRMJ56kr6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b40e35f-3657-4988-9712-399f1af6fa95"
      },
      "source": [
        "# Initialize model using CPU\n",
        "mlp_on_cpu = MLP(size_input, size_hidden, size_output, device='cpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(1234)).batch(20)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_cpu.forward(inputs)\n",
        "    loss_total = loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
        "    mlp_on_cpu.backward(inputs, outputs)\n",
        "  print('Number of Epoch = {} - Average MSE:= {}'.format(epoch + 1, np.sum(loss_total) / X_train.shape[0]))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Average MSE:= 3263.0756666666666\n",
            "Number of Epoch = 2 - Average MSE:= 3.3917197265625\n",
            "Number of Epoch = 3 - Average MSE:= 2.0919254557291667\n",
            "Number of Epoch = 4 - Average MSE:= 1.4363487955729166\n",
            "Number of Epoch = 5 - Average MSE:= 1.0708619791666667\n",
            "Number of Epoch = 6 - Average MSE:= 0.84127099609375\n",
            "Number of Epoch = 7 - Average MSE:= 0.6861051432291667\n",
            "Number of Epoch = 8 - Average MSE:= 0.57770654296875\n",
            "Number of Epoch = 9 - Average MSE:= 0.49791581217447917\n",
            "Number of Epoch = 10 - Average MSE:= 0.43906884765625\n",
            "\n",
            "Total time taken (in seconds): 9.63\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdMFAuH18Ve0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "916669fa-35eb-409d-d492-b0acc5a73e01"
      },
      "source": [
        "# Initialize model using GPU\n",
        "mlp_on_gpu = MLP(size_input, size_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(1234)).batch(20)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_gpu.loss(preds, outputs)\n",
        "    mlp_on_gpu.backward(inputs, outputs)\n",
        "  print('Number of Epoch = {} - Average MSE:= {}'.format(epoch + 1, np.sum(loss_total_gpu) / X_train.shape[0]))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Average MSE:= 1290.1395833333333\n",
            "Number of Epoch = 2 - Average MSE:= 5.1521702473958335\n",
            "Number of Epoch = 3 - Average MSE:= 2.7800074869791667\n",
            "Number of Epoch = 4 - Average MSE:= 1.8930498046875\n",
            "Number of Epoch = 5 - Average MSE:= 1.4884049479166668\n",
            "Number of Epoch = 6 - Average MSE:= 1.2521775716145833\n",
            "Number of Epoch = 7 - Average MSE:= 1.08763671875\n",
            "Number of Epoch = 8 - Average MSE:= 0.967400146484375\n",
            "Number of Epoch = 9 - Average MSE:= 0.8733599446614584\n",
            "Number of Epoch = 10 - Average MSE:= 0.7980319010416667\n",
            "\n",
            "Total time taken (in seconds): 6.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI4lsqPhB6Xi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "349fbd64-7255-453e-c899-e315b708ce2a"
      },
      "source": [
        "#Default mode\n",
        "mlp_on_default = MLP(size_input, size_hidden, size_output)\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(1234)).batch(20)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_default.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_default.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_default.loss(preds, outputs)\n",
        "    mlp_on_default.backward(inputs, outputs)\n",
        "  print('Number of Epoch = {} - Average MSE:= {}'.format(epoch + 1, np.sum(loss_total_gpu) / X_train.shape[0]))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Average MSE:= 2254.8335\n",
            "Number of Epoch = 2 - Average MSE:= 4.836892578125\n",
            "Number of Epoch = 3 - Average MSE:= 3.1178499348958333\n",
            "Number of Epoch = 4 - Average MSE:= 2.2547076822916665\n",
            "Number of Epoch = 5 - Average MSE:= 1.7371930338541666\n",
            "Number of Epoch = 6 - Average MSE:= 1.4146031901041667\n",
            "Number of Epoch = 7 - Average MSE:= 1.19491064453125\n",
            "Number of Epoch = 8 - Average MSE:= 1.031443603515625\n",
            "Number of Epoch = 9 - Average MSE:= 0.9095869140625\n",
            "Number of Epoch = 10 - Average MSE:= 0.8118401692708334\n",
            "\n",
            "Total time taken (in seconds): 5.42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkaUg-TY7GdV",
        "outputId": "154109d6-8dd9-422f-ce82-c1db9f31162c"
      },
      "source": [
        "#TPU mode\n",
        "mlp_on_gpu = MLP(size_input, size_hidden, size_output, device='tpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(1234)).batch(20)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_gpu.loss(preds, outputs)\n",
        "    mlp_on_gpu.backward(inputs, outputs)\n",
        "  print('Number of Epoch = {} - Average MSE:= {}'.format(epoch + 1, np.sum(loss_total_gpu) / X_train.shape[0]))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Average MSE:= 1923.8008333333332\n",
            "Number of Epoch = 2 - Average MSE:= 1.804669921875\n",
            "Number of Epoch = 3 - Average MSE:= 1.12889501953125\n",
            "Number of Epoch = 4 - Average MSE:= 0.903534912109375\n",
            "Number of Epoch = 5 - Average MSE:= 0.7862600911458333\n",
            "Number of Epoch = 6 - Average MSE:= 0.7082796223958333\n",
            "Number of Epoch = 7 - Average MSE:= 0.6476110026041667\n",
            "Number of Epoch = 8 - Average MSE:= 0.5970179036458333\n",
            "Number of Epoch = 9 - Average MSE:= 0.554156005859375\n",
            "Number of Epoch = 10 - Average MSE:= 0.5169111735026042\n",
            "\n",
            "Total time taken (in seconds): 7.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXe-2MENCOjq"
      },
      "source": [
        "## One Step Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKxWn7CNDVN5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56e34a10-2f3c-4ed1-d605-8eef85fa5f3e"
      },
      "source": [
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_default.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  test_loss_total = test_loss_total + mlp_on_default.loss(preds, outputs)\n",
        "# a = (test_loss_total.numpy() / X_train.shape[0])\n",
        "# print(X_train.shape[0])\n",
        "# print(test_loss_total.numpy())\n",
        "# print(b)\n",
        "print('Test MSE: {:.4f}'.format(np.sum(test_loss_total.numpy()) / X_train.shape[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test MSE: 0.3073\n"
          ]
        }
      ]
    }
  ]
}